import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.feature_selection import SelectKBest, f_regression
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class MarketMLAnalyzer:
    def __init__(self, csv_file_path):
        """
        åˆå§‹åŒ–æœºå™¨å­¦ä¹ åˆ†æå™¨
        
        Args:
            csv_file_path: CSVæ–‡ä»¶è·¯å¾„
        """
        self.csv_file_path = csv_file_path
        self.df = None
        self.X = None
        self.y = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.scaler = StandardScaler()
        self.models = {}
        self.best_model = None
        self.feature_importance = None
        
    def load_and_prepare_data(self):
        """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
        print("ğŸ”„ åŠ è½½å’Œé¢„å¤„ç†æ•°æ®...")
        
        try:
            # åŠ è½½æ•°æ®
            self.df = pd.read_csv(self.csv_file_path)
            print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®: {len(self.df)} æ¡è®°å½•")
            
            # æ•°æ®åŸºæœ¬ä¿¡æ¯
            print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {self.df.shape}")
            print(f"ğŸ“… æ—¶é—´èŒƒå›´: {self.df['created_at'].min()} åˆ° {self.df['created_at'].max()}")
            
            # æ•°æ®é¢„å¤„ç†
            self._preprocess_data()
            
            # ç‰¹å¾å·¥ç¨‹
            self._feature_engineering()
            
            # å‡†å¤‡è®­ç»ƒæ•°æ®
            self._prepare_training_data()
            
            print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
            return False
            
        return True
    
    def _preprocess_data(self):
        """æ•°æ®é¢„å¤„ç†"""
        print("ğŸ”§ è¿›è¡Œæ•°æ®é¢„å¤„ç†...")
        
        # è½¬æ¢æ—¶é—´åˆ—
        self.df['created_at'] = pd.to_datetime(self.df['created_at'])
        self.df['insert_time'] = pd.to_datetime(self.df['insert_time'])
        
        # æ’åº
        self.df = self.df.sort_values('created_at').reset_index(drop=True)
        
        # å¤„ç†ç¼ºå¤±å€¼
        self.df = self.df.dropna()
        
        # æ•°æ®ç±»å‹è½¬æ¢
        self.df['quantity'] = pd.to_numeric(self.df['quantity'], errors='coerce')
        self.df['price_per_unit'] = pd.to_numeric(self.df['price_per_unit'], errors='coerce')
        self.df['price'] = pd.to_numeric(self.df['price'], errors='coerce')
        self.df['has_sold'] = self.df['has_sold'].astype(int)
        
        # ç§»é™¤å¼‚å¸¸å€¼
        self._remove_outliers()
        
        print(f"ğŸ“Š é¢„å¤„ç†åæ•°æ®å½¢çŠ¶: {self.df.shape}")
    
    def _remove_outliers(self):
        """ç§»é™¤å¼‚å¸¸å€¼"""
        print("ğŸ” æ£€æµ‹å’Œç§»é™¤å¼‚å¸¸å€¼...")
        
        # ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
        numeric_columns = ['quantity', 'price_per_unit', 'price']
        
        for col in numeric_columns:
            Q1 = self.df[col].quantile(0.25)
            Q3 = self.df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = (self.df[col] < lower_bound) | (self.df[col] > upper_bound)
            outlier_count = outliers.sum()
            
            if outlier_count > 0:
                print(f"  {col}: å‘ç° {outlier_count} ä¸ªå¼‚å¸¸å€¼")
                self.df = self.df[~outliers]
        
        print(f"ğŸ“Š ç§»é™¤å¼‚å¸¸å€¼åæ•°æ®å½¢çŠ¶: {self.df.shape}")
    
    def _feature_engineering(self):
        """ç‰¹å¾å·¥ç¨‹"""
        print("âš™ï¸ è¿›è¡Œç‰¹å¾å·¥ç¨‹...")
        
        # æ—¶é—´ç‰¹å¾
        self.df['hour'] = self.df['created_at'].dt.hour
        self.df['day_of_week'] = self.df['created_at'].dt.dayofweek
        self.df['day_of_month'] = self.df['created_at'].dt.day
        self.df['month'] = self.df['created_at'].dt.month
        
        # ä»·æ ¼ç›¸å…³ç‰¹å¾
        self.df['price_quantity_ratio'] = self.df['price'] / (self.df['quantity'] + 1)
        self.df['price_per_unit_squared'] = self.df['price_per_unit'] ** 2
        self.df['quantity_squared'] = self.df['quantity'] ** 2
        
        # ç§»åŠ¨å¹³å‡ç‰¹å¾
        for window in [3, 7, 14]:
            self.df[f'price_ma_{window}'] = self.df['price_per_unit'].rolling(window=window).mean()
            self.df[f'quantity_ma_{window}'] = self.df['quantity'].rolling(window=window).mean()
        
        # ä»·æ ¼å˜åŒ–ç‰¹å¾
        self.df['price_change'] = self.df['price_per_unit'].diff()
        self.df['price_change_pct'] = self.df['price_per_unit'].pct_change()
        
        # æ³¢åŠ¨æ€§ç‰¹å¾
        for window in [5, 10]:
            self.df[f'price_volatility_{window}'] = self.df['price_per_unit'].rolling(window=window).std()
        
        # å¡«å……ç¼ºå¤±å€¼
        self.df = self.df.fillna(method='ffill').fillna(method='bfill')
        
        print("âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ")
    
    def _prepare_training_data(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        # é€‰æ‹©ç‰¹å¾
        feature_columns = [
            'quantity', 'price_per_unit', 'has_sold',
            'hour', 'day_of_week', 'day_of_month', 'month',
            'price_quantity_ratio', 'price_per_unit_squared', 'quantity_squared',
            'price_ma_3', 'price_ma_7', 'price_ma_14',
            'quantity_ma_3', 'quantity_ma_7', 'quantity_ma_14',
            'price_change', 'price_change_pct',
            'price_volatility_5', 'price_volatility_10'
        ]
        
        # ç§»é™¤åŒ…å«NaNçš„åˆ—
        available_features = [col for col in feature_columns if col in self.df.columns]
        self.X = self.df[available_features].fillna(0)
        self.y = self.df['price_per_unit']
        
        print(f"ğŸ“Š ç‰¹å¾æ•°é‡: {len(available_features)}")
        print(f"ğŸ“Š æ ·æœ¬æ•°é‡: {len(self.X)}")
        
        # åˆ†å‰²æ•°æ®
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            self.X, self.y, test_size=0.2, random_state=42, shuffle=False
        )
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        self.X_train_scaled = self.scaler.fit_transform(self.X_train)
        self.X_test_scaled = self.scaler.transform(self.X_test)
        
        print("âœ… è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ")
    
    def train_models(self):
        """è®­ç»ƒå¤šä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹"""
        print("ğŸ¤– å¼€å§‹è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹...")
        
        # å®šä¹‰æ¨¡å‹
        models = {
            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
            'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),
            'Linear Regression': LinearRegression(),
            'Ridge Regression': Ridge(alpha=1.0),
            'Lasso Regression': Lasso(alpha=0.1),
            'SVR': SVR(kernel='rbf', C=1.0, gamma='scale')
        }
        
        # è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹
        model_scores = {}
        
        for name, model in models.items():
            print(f"ğŸ”„ è®­ç»ƒ {name}...")
            
            try:
                # è®­ç»ƒæ¨¡å‹
                if name == 'SVR':
                    model.fit(self.X_train_scaled, self.y_train)
                    y_pred = model.predict(self.X_test_scaled)
                else:
                    model.fit(self.X_train, self.y_train)
                    y_pred = model.predict(self.X_test)
                
                # è¯„ä¼°æ¨¡å‹
                mae = mean_absolute_error(self.y_test, y_pred)
                mse = mean_squared_error(self.y_test, y_pred)
                rmse = np.sqrt(mse)
                r2 = r2_score(self.y_test, y_pred)
                
                model_scores[name] = {
                    'model': model,
                    'mae': mae,
                    'mse': mse,
                    'rmse': rmse,
                    'r2': r2,
                    'predictions': y_pred
                }
                
                print(f"  âœ… {name}: MAE={mae:.2f}, RMSE={rmse:.2f}, RÂ²={r2:.3f}")
                
            except Exception as e:
                print(f"  âŒ {name} è®­ç»ƒå¤±è´¥: {str(e)}")
        
        self.models = model_scores
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        best_model_name = max(model_scores.keys(), key=lambda x: model_scores[x]['r2'])
        self.best_model = model_scores[best_model_name]['model']
        
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model_name}")
        print(f"ğŸ“Š æœ€ä½³æ¨¡å‹æ€§èƒ½: RÂ²={model_scores[best_model_name]['r2']:.3f}")
        
        return model_scores
    
    def hyperparameter_tuning(self):
        """è¶…å‚æ•°è°ƒä¼˜"""
        print("âš™ï¸ å¼€å§‹è¶…å‚æ•°è°ƒä¼˜...")
        
        if self.best_model is None:
            print("âŒ è¯·å…ˆè®­ç»ƒæ¨¡å‹")
            return None
        
        # æ ¹æ®æœ€ä½³æ¨¡å‹ç±»å‹è¿›è¡Œè°ƒä¼˜
        if isinstance(self.best_model, RandomForestRegressor):
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [10, 20, None],
                'min_samples_split': [2, 5, 10]
            }
            model = RandomForestRegressor(random_state=42)
            
        elif isinstance(self.best_model, GradientBoostingRegressor):
            param_grid = {
                'n_estimators': [50, 100, 200],
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 5, 7]
            }
            model = GradientBoostingRegressor(random_state=42)
            
        else:
            print("âš ï¸ å½“å‰æœ€ä½³æ¨¡å‹ä¸æ”¯æŒè¶…å‚æ•°è°ƒä¼˜")
            return self.best_model
        
        # ç½‘æ ¼æœç´¢
        grid_search = GridSearchCV(
            model, param_grid, cv=5, scoring='r2', n_jobs=-1
        )
        
        grid_search.fit(self.X_train, self.y_train)
        
        print(f"âœ… æœ€ä½³å‚æ•°: {grid_search.best_params_}")
        print(f"ğŸ“Š æœ€ä½³åˆ†æ•°: {grid_search.best_score_:.3f}")
        
        self.best_model = grid_search.best_estimator_
        return self.best_model
    
    def analyze_feature_importance(self):
        """åˆ†æç‰¹å¾é‡è¦æ€§"""
        print("ğŸ” åˆ†æç‰¹å¾é‡è¦æ€§...")
        
        if self.best_model is None:
            print("âŒ è¯·å…ˆè®­ç»ƒæ¨¡å‹")
            return None
        
        if hasattr(self.best_model, 'feature_importances_'):
            self.feature_importance = pd.DataFrame({
                'feature': self.X.columns,
                'importance': self.best_model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            print("ğŸ“Š ç‰¹å¾é‡è¦æ€§æ’åº:")
            print(self.feature_importance.head(10))
            
        else:
            print("âš ï¸ å½“å‰æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§åˆ†æ")
        
        return self.feature_importance
    
    def predict_future_prices(self, days_ahead=7):
        """é¢„æµ‹æœªæ¥ä»·æ ¼ - æ”¹è¿›ç‰ˆæ—¶é—´åºåˆ—é¢„æµ‹"""
        print(f"ğŸ”® é¢„æµ‹æœªæ¥ {days_ahead} å¤©çš„ä»·æ ¼...")
        
        if self.best_model is None:
            print("âŒ è¯·å…ˆè®­ç»ƒæ¨¡å‹")
            return None
        
        # ä½¿ç”¨æ—¶é—´åºåˆ—æ–¹æ³•è¿›è¡Œé¢„æµ‹
        predictions = []
        confidence_intervals = []
        
        # è·å–å†å²ä»·æ ¼æ•°æ®
        historical_prices = self.df['price_per_unit'].values
        historical_dates = self.df['created_at'].values
        
        # è®¡ç®—ä»·æ ¼è¶‹åŠ¿
        recent_prices = historical_prices[-30:]  # æœ€è¿‘30ä¸ªæ•°æ®ç‚¹
        if len(recent_prices) > 1:
            # è®¡ç®—è¶‹åŠ¿
            trend = np.polyfit(range(len(recent_prices)), recent_prices, 1)[0]
            volatility = np.std(recent_prices)
            mean_price = np.mean(recent_prices)
        else:
            trend = 0
            volatility = 0
            mean_price = historical_prices[-1]
        
        print(f"ğŸ“Š ä»·æ ¼è¶‹åŠ¿åˆ†æ:")
        print(f"  æœ€è¿‘ä»·æ ¼å‡å€¼: {mean_price:.2f}")
        print(f"  ä»·æ ¼è¶‹åŠ¿: {trend:+.4f} æ¯å•ä½æ—¶é—´")
        print(f"  ä»·æ ¼æ³¢åŠ¨æ€§: {volatility:.2f}")
        
        # ç”Ÿæˆé¢„æµ‹
        for day in range(days_ahead):
            # åŸºç¡€é¢„æµ‹ï¼šä½¿ç”¨è¶‹åŠ¿
            base_prediction = mean_price + trend * (day + 1)
            
            # æ·»åŠ éšæœºæ³¢åŠ¨ï¼ˆåŸºäºå†å²æ³¢åŠ¨æ€§ï¼‰
            if volatility > 0:
                noise = np.random.normal(0, volatility * 0.1)  # 10%çš„æ³¢åŠ¨
                prediction = base_prediction + noise
            else:
                prediction = base_prediction
            
            # ç¡®ä¿é¢„æµ‹ä»·æ ¼åˆç†ï¼ˆä¸èƒ½ä¸ºè´Ÿæ•°ï¼‰
            prediction = max(prediction, 0.01)
            
            predictions.append(prediction)
            
            # è®¡ç®—ç½®ä¿¡åŒºé—´
            if volatility > 0:
                ci_lower = prediction - 1.96 * volatility * 0.1
                ci_upper = prediction + 1.96 * volatility * 0.1
            else:
                ci_lower = prediction * 0.95
                ci_upper = prediction * 1.05
            
            confidence_intervals.append((ci_lower, ci_upper))
        
        # åˆ›å»ºé¢„æµ‹ç»“æœ
        future_dates = pd.date_range(
            start=self.df['created_at'].max() + pd.Timedelta(days=1),
            periods=days_ahead,
            freq='D'
        )
        
        predictions_df = pd.DataFrame({
            'date': future_dates,
            'predicted_price': predictions,
            'ci_lower': [ci[0] for ci in confidence_intervals],
            'ci_upper': [ci[1] for ci in confidence_intervals]
        })
        
        print("âœ… ä»·æ ¼é¢„æµ‹å®Œæˆ")
        return predictions_df
    
    def plot_analysis(self):
        """ç»˜åˆ¶åˆ†æå›¾è¡¨"""
        print("ğŸ“Š ç»˜åˆ¶åˆ†æå›¾è¡¨...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. ä»·æ ¼æ—¶é—´åºåˆ—
        axes[0, 0].plot(self.df['created_at'], self.df['price_per_unit'], alpha=0.7)
        axes[0, 0].set_title('Price Time Series', fontsize=14, fontweight='bold')
        axes[0, 0].set_xlabel('Date')
        axes[0, 0].set_ylabel('Price per Unit')
        axes[0, 0].tick_params(axis='x', rotation=45)
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. ä»·æ ¼åˆ†å¸ƒ
        axes[0, 1].hist(self.df['price_per_unit'], bins=50, alpha=0.7, edgecolor='black')
        axes[0, 1].set_title('Price Distribution', fontsize=14, fontweight='bold')
        axes[0, 1].set_xlabel('Price per Unit')
        axes[0, 1].set_ylabel('Frequency')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ
        if self.models:
            model_names = list(self.models.keys())
            r2_scores = [self.models[name]['r2'] for name in model_names]
            
            bars = axes[1, 0].bar(model_names, r2_scores, alpha=0.7)
            axes[1, 0].set_title('Model Performance (RÂ² Score)', fontsize=14, fontweight='bold')
            axes[1, 0].set_ylabel('RÂ² Score')
            axes[1, 0].tick_params(axis='x', rotation=45)
            axes[1, 0].grid(True, alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, score in zip(bars, r2_scores):
                axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                               f'{score:.3f}', ha='center', va='bottom')
        
        # 4. ç‰¹å¾é‡è¦æ€§
        if self.feature_importance is not None:
            top_features = self.feature_importance.head(10)
            axes[1, 1].barh(range(len(top_features)), top_features['importance'])
            axes[1, 1].set_yticks(range(len(top_features)))
            axes[1, 1].set_yticklabels(top_features['feature'])
            axes[1, 1].set_title('Top 10 Feature Importance', fontsize=14, fontweight='bold')
            axes[1, 1].set_xlabel('Importance')
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def plot_predictions(self, predictions_df):
        """ç»˜åˆ¶é¢„æµ‹ç»“æœ - æ”¹è¿›ç‰ˆ"""
        print("ğŸ“ˆ ç»˜åˆ¶é¢„æµ‹ç»“æœ...")
        
        fig, axes = plt.subplots(2, 1, figsize=(15, 12))
        
        # 1. å†å²ä»·æ ¼å’Œé¢„æµ‹ï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰
        axes[0].plot(self.df['created_at'], self.df['price_per_unit'], 
                    label='Historical Price', alpha=0.7, linewidth=1, color='blue')
        
        # é¢„æµ‹ä»·æ ¼
        axes[0].plot(predictions_df['date'], predictions_df['predicted_price'], 
                    label='Predicted Price', color='red', linewidth=2, linestyle='-', marker='o')
        
        # ç½®ä¿¡åŒºé—´
        if 'ci_lower' in predictions_df.columns:
            axes[0].fill_between(predictions_df['date'], 
                               predictions_df['ci_lower'], 
                               predictions_df['ci_upper'], 
                               alpha=0.3, color='red', label='95% Confidence Interval')
        
        axes[0].set_title('Price History and Future Prediction with Confidence Interval', 
                         fontsize=14, fontweight='bold')
        axes[0].set_xlabel('Date')
        axes[0].set_ylabel('Price per Unit')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        axes[0].tick_params(axis='x', rotation=45)
        
        # 2. é¢„æµ‹è¶‹åŠ¿åˆ†æï¼ˆæ›´è¯¦ç»†ï¼‰
        axes[1].plot(predictions_df['date'], predictions_df['predicted_price'], 
                    marker='o', linewidth=3, markersize=8, color='red', label='Predicted Price')
        
        # æ·»åŠ è¶‹åŠ¿çº¿
        if len(predictions_df) > 1:
            x_numeric = range(len(predictions_df))
            z = np.polyfit(x_numeric, predictions_df['predicted_price'], 1)
            trend_line = np.poly1d(z)
            axes[1].plot(predictions_df['date'], trend_line(x_numeric), 
                        '--', color='orange', linewidth=2, alpha=0.8, 
                        label=f'Trend: {"ä¸Šå‡" if z[0] > 0 else "ä¸‹é™"} ({z[0]:.2f}/day)')
        
        axes[1].set_title('Future Price Trend Analysis', fontsize=14, fontweight='bold')
        axes[1].set_xlabel('Date')
        axes[1].set_ylabel('Predicted Price')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        axes[1].tick_params(axis='x', rotation=45)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        current_price = self.df['price_per_unit'].iloc[-1]
        future_price = predictions_df['predicted_price'].iloc[-1]
        price_change = future_price - current_price
        price_change_pct = (price_change / current_price) * 100
        
        # è®¡ç®—ä»·æ ¼èŒƒå›´
        min_pred = predictions_df['predicted_price'].min()
        max_pred = predictions_df['predicted_price'].max()
        price_range = max_pred - min_pred
        
        stats_text = f'''Current: {current_price:.2f}
Future: {future_price:.2f}
Change: {price_change:+.2f} ({price_change_pct:+.1f}%)
Range: {min_pred:.2f} - {max_pred:.2f}
Volatility: {price_range:.2f}'''
        
        axes[1].text(0.02, 0.98, stats_text, transform=axes[1].transAxes, 
                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))
        
        plt.tight_layout()
        plt.show()
        
        # æ‰“å°è¯¦ç»†é¢„æµ‹ç»“æœ
        print(f"\nğŸ“Š è¯¦ç»†é¢„æµ‹ç»“æœ:")
        print(f"å½“å‰ä»·æ ¼: {current_price:.2f}")
        print(f"é¢„æµ‹ä»·æ ¼èŒƒå›´: {min_pred:.2f} - {max_pred:.2f}")
        print(f"æœ€ç»ˆé¢„æµ‹ä»·æ ¼: {future_price:.2f}")
        print(f"ä»·æ ¼å˜åŒ–: {price_change:+.2f} ({price_change_pct:+.1f}%)")
        print(f"é¢„æµ‹æ³¢åŠ¨æ€§: {price_range:.2f}")
        
        # æ˜¾ç¤ºæ¯æ—¥é¢„æµ‹
        print(f"\nğŸ“… æ¯æ—¥é¢„æµ‹è¯¦æƒ…:")
        for i, row in predictions_df.iterrows():
            print(f"  {row['date'].strftime('%Y-%m-%d')}: {row['predicted_price']:.2f}")
        
        return predictions_df
    
    def generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("ğŸ“‹ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        report = f"""
        ========================================
        æœºå™¨å­¦ä¹ ä»·æ ¼é¢„æµ‹åˆ†ææŠ¥å‘Š
        ========================================
        
        æ•°æ®æ¦‚è§ˆ:
        - æ€»è®°å½•æ•°: {len(self.df)}
        - æ—¶é—´èŒƒå›´: {self.df['created_at'].min()} åˆ° {self.df['created_at'].max()}
        - ç‰¹å¾æ•°é‡: {len(self.X.columns)}
        
        æ¨¡å‹æ€§èƒ½:
        """
        
        if self.models:
            for name, metrics in self.models.items():
                report += f"        - {name}: RÂ²={metrics['r2']:.3f}, RMSE={metrics['rmse']:.2f}\n"
        
        if self.feature_importance is not None:
            report += f"\n        é‡è¦ç‰¹å¾ (å‰5ä¸ª):\n"
            for i, row in self.feature_importance.head(5).iterrows():
                report += f"        - {row['feature']}: {row['importance']:.3f}\n"
        
        report += f"\n        æ•°æ®è´¨é‡:\n"
        report += f"        - ç¼ºå¤±å€¼: {self.df.isnull().sum().sum()}\n"
        report += f"        - å¼‚å¸¸å€¼: å·²å¤„ç†\n"
        report += f"        - æ•°æ®å®Œæ•´æ€§: {((len(self.df) - self.df.isnull().sum().sum()) / (len(self.df) * len(self.df.columns)) * 100):.1f}%\n"
        
        print(report)
        return report
    
    def run_complete_analysis(self, days_ahead=7):
        """è¿è¡Œå®Œæ•´çš„æœºå™¨å­¦ä¹ åˆ†æ"""
        print("ğŸš€ å¼€å§‹å®Œæ•´çš„æœºå™¨å­¦ä¹ åˆ†æ...")
        print("=" * 50)
        
        # 1. åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
        if not self.load_and_prepare_data():
            return None
        
        # 2. è®­ç»ƒæ¨¡å‹
        model_scores = self.train_models()
        
        # 3. è¶…å‚æ•°è°ƒä¼˜
        self.hyperparameter_tuning()
        
        # 4. ç‰¹å¾é‡è¦æ€§åˆ†æ
        self.analyze_feature_importance()
        
        # 5. é¢„æµ‹æœªæ¥ä»·æ ¼
        predictions = self.predict_future_prices(days_ahead)
        
        # 6. ç»˜åˆ¶åˆ†æå›¾è¡¨
        self.plot_analysis()
        
        # 7. ç»˜åˆ¶é¢„æµ‹ç»“æœ
        if predictions is not None:
            self.plot_predictions(predictions)
        
        # 8. ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
        
        print("âœ… æœºå™¨å­¦ä¹ åˆ†æå®Œæˆ!")
        return predictions


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– æœºå™¨å­¦ä¹ ä»·æ ¼é¢„æµ‹ç³»ç»Ÿ")
    print("=" * 50)
    
    # é€‰æ‹©CSVæ–‡ä»¶
    csv_files = ['iron_ore.csv', 'cobalt_ore.csv']
    
    print("å¯ç”¨çš„æ•°æ®æ–‡ä»¶:")
    for i, file in enumerate(csv_files, 1):
        print(f"{i}. {file}")
    
    try:
        choice = int(input("è¯·é€‰æ‹©æ•°æ®æ–‡ä»¶ (è¾“å…¥æ•°å­—): ")) - 1
        if 0 <= choice < len(csv_files):
            csv_file = csv_files[choice]
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤æ–‡ä»¶: iron_ore.csv")
            csv_file = 'iron_ore.csv'
    except:
        print("ä½¿ç”¨é»˜è®¤æ–‡ä»¶: iron_ore.csv")
        csv_file = 'iron_ore.csv'
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = MarketMLAnalyzer(csv_file)
    
    # è¿è¡Œå®Œæ•´åˆ†æ
    predictions = analyzer.run_complete_analysis(days_ahead=7)
    
    if predictions is not None:
        print(f"\nğŸ¯ é¢„æµ‹å®Œæˆ! æœªæ¥7å¤©çš„ä»·æ ¼é¢„æµ‹å·²ç”Ÿæˆ")
        print(predictions)


if __name__ == "__main__":
    main()
